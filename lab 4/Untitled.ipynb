{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 9.],\n",
       "       [1., 5.],\n",
       "       [3., 6.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x is input\n",
    "# y is output\n",
    "x=np.array(([2,9],[1,5],[3,6]),dtype=float)\n",
    "y=np.array(([92],[86],[89]),dtype=float)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[92.],\n",
       "       [86.],\n",
       "       [89.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 9.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize value means value should be between o and 1\n",
    "c=np.max(x,axis=0)# to check maximum value column wise\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22222222, 0.11111111],\n",
       "       [0.11111111, 0.0617284 ],\n",
       "       [0.33333333, 0.07407407]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=x/c\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0092],\n",
       "       [0.0086],\n",
       "       [0.0089]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=y/100 # normalize the output value by 100 beacuse maximum marks is 100\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x): # finding activation function\n",
    "    return 1/1+np.exp(-x)\n",
    "def sigmoid_grad(x):# think it has diffrenciation during back propagation\n",
    "    return x*(1-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch=7000 # number of iteration \n",
    "eta=0.1# learning rate\n",
    "input_neurons = 2\n",
    "hidden_neurons = 3\n",
    "output_neurons = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.54923597, 0.75484849, 0.83385038],\n",
       "       [0.07515447, 0.30850947, 0.4431128 ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wh=np.random.uniform(size=(input_neurons,hidden_neurons))# wight at hidden is the size between input and hidden\n",
    "wh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97116601, 0.67757731, 0.03521903]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bh=np.random.uniform(size=(1,hidden_neurons))# bias at hidden\n",
    "bh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights from hidden to Output Layer:\n",
      " [[0.24136229]\n",
      " [0.68967786]\n",
      " [0.9916053 ]]\n"
     ]
    }
   ],
   "source": [
    "wout = np.random.uniform(size = (hidden_neurons, output_neurons))\n",
    "print(\"Weights from hidden to Output Layer:\\n\",wout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Bias:\n",
      " [[0.39607037]]\n"
     ]
    }
   ],
   "source": [
    "bout = np.random.uniform(size = (1, output_neurons))\n",
    "print(\"Output Bias:\\n\",bout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(epoch):\n",
    "    #forward pass\n",
    "    print(\"\\n\\t( EPOCH {} of {} )\".format(i+1, epoch))\n",
    "    h_ip = np.dot(x, wh) + bh # to find hidden input value=dot product of input * weight at hidden + bais at hidden\n",
    "    print(\"h_ip:\\n\", h_ip)\n",
    "    h_act = sigmoid(h_ip)# activation for hidden value\n",
    "    o_ip = np.dot(h_act, wout) + bout \n",
    "    output = sigmoid(o_ip)\n",
    "    ###########################################\n",
    "    eo = y - output # finding error at output layer where y is actual output \n",
    "    out_grad = sigmoid_grad(output) # diffrenctiating the output \n",
    "    d_output = eo * out_grad# getting delta out put = error * gradient output \n",
    "    print(\"Output:\\n\", d_output)\n",
    "    eh = d_output.dot(wout.T) # finding error at hidden layer \n",
    "    hidden_grad = sigmoid_grad(h_act)\n",
    "    d_hidden = eh * hidden_grad # same as above \n",
    "    wout += h_act.T.dot(d_output) * eta #\n",
    "    wh += x.T.dot(d_hidden) * eta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
